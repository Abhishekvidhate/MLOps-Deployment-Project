Large language models (LLMs) have undoubtedly changed the way we interact with information. However, they come with their fair share of limitations as to what we can ask of them. Base LLMs (ex. Llama-2-70b, gpt-4, etc.) are only aware of the information that they've been trained on and will fall short when we require them to know information beyond that. Retrieval augmented generation (RAG) based LLM applications address this exact issue and extend the utility of LLMs to our specific data sources. 

we're going to build a RAG-based LLM application where we will incorporate external data sources to augment our LLMâ€™s capabilities. Specifically, we will be building an assistant that can answer questions about Scikit-Learn, as scikit learn's documentation is overwhekming for beginner in ML

[reference/inspiration- MadeWithML](https://madewithml.com/#course)

